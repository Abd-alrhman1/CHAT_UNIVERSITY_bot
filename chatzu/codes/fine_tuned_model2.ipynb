{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwxreMtFGepO",
        "outputId": "ddcc4f5f-8dbe-49de-dbb1-1b0265793cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vhI34c9OIV5I",
        "outputId": "548f63d5-b4f1-498c-897d-03e1d861316a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7uNUNcaI_co"
      },
      "outputs": [],
      "source": [
        "!pip install unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dqLEaKaJPnj"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from huggingface_hub import notebook_login\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgAVC92mJqNg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import unsloth\n",
        "from unsloth import FastLanguageModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6xMcwnlMSIK"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bits = True\n",
        "model,tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8b\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bits,\n",
        "    token = HF_TOKEN\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbk945KONKvf"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(model,\n",
        "                                    r=16,\n",
        "                                    target_modules = [\n",
        "                                        \"q_proj\",\n",
        "                                        \"k_proj\",\n",
        "                                        \"v_proj\",\n",
        "                                        \"o_proj\",\n",
        "                                        \"gate_proj\",\n",
        "                                        \"up_proj\",\n",
        "                                        \"down_proj\",\n",
        "                                    ],\n",
        "                                    lora_alpha = 16,\n",
        "                                    lora_dropout = 0.05,\n",
        "                                    bias = \"none\",\n",
        "                                    use_gradient_checkpointing = \"unsloth\",\n",
        "                                    random_state=3407,\n",
        "                                    use_rslora=False,\n",
        "                                    loftq_config=None\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0OswizuO4so"
      },
      "outputs": [],
      "source": [
        "prompt_style = \"\"\"below is an instruction that describes a task ,paored with an input that provides further context.write a response that appropriately completes the request.before answering ,think carefully about the question and create a step-by-step cahin of thoughts to ensurea logical and accurate response.\n",
        "\n",
        "##instruction:\n",
        "you are an acadamice chatbot for zarqa university and your name is chat zu from now on you can anwser any thing about the university but always remind the user that your a zarqa chat bot when ever they ask for anything not about the university allways trie to get students and there perints to join the university try to be as helpfull, use the zarqa university to answer relevent questions,i add a algorithem to predict what courses should the student takeand to find out if the lecyurers are avalable.\n",
        "\n",
        "##Topic:\n",
        "{}\n",
        "\n",
        "##Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPYtWFZr_lz0"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/Data.zip\"\n",
        "\n",
        "# Changed extract_dir to be a directory\n",
        "extract_dir = \"/content/\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Files extracted to {extract_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41ffVM6vJHIR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def txt_folder_to_proper_json(folder_path, output_json_path):\n",
        "    \"\"\"\n",
        "    Convert all txt files in a folder to proper JSON format with combined objects.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing txt files\n",
        "        output_json_path (str): Path where to save the output JSON file\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    # Loop through all files in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Read the file content\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            # Create single object with both properties\n",
        "            file_data = {\n",
        "                \"name\": filename,\n",
        "                \"text\": content\n",
        "            }\n",
        "            data.append(file_data)\n",
        "\n",
        "    # Write to JSON file\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
        "        json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "# Example usage:\n",
        "txt_folder_path = '/content/Data'\n",
        "output_json_path = '/content/output.json'\n",
        "txt_folder_to_proper_json(txt_folder_path, output_json_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZsfKwIWSdJh"
      },
      "outputs": [],
      "source": [
        "with open('output.json', 'r') as f:\n",
        "    files_data = json.load(f)\n",
        "\n",
        "for file_obj in files_data:\n",
        "    print(f\"Filename: {file_obj['name']}\")\n",
        "    print(f\"Content: {file_obj['text'][:100]}...\")  # First 100 chars\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDVy4NvISmzJ"
      },
      "outputs": [],
      "source": [
        "files_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OcbYFIkJN2R"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def load_json_file(json_path):\n",
        "    \"\"\"\n",
        "    Load the JSON file and return its contents\n",
        "\n",
        "    Args:\n",
        "        json_path (str): Path to the JSON file\n",
        "\n",
        "    Returns:\n",
        "        The parsed JSON data\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r', encoding='utf-8') as json_file:\n",
        "        data = json.load(json_file)\n",
        "    return data\n",
        "\n",
        "\n",
        "data = load_json_file('/content/output.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY0tGP0AS93p"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QdoLSzIMT8y"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(data), 2):\n",
        "    name_entry = data[i]\n",
        "    text_entry = data[i]\n",
        "\n",
        "    filename = name_entry['name']\n",
        "    content = text_entry['text']\n",
        "\n",
        "    print(f\"File: {filename}\")\n",
        "    print(f\"Content: {content[:50]}...\")  # Print first 50 chars\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgKhGVe-qszN"
      },
      "outputs": [],
      "source": [
        "#EOS = tokenizer.eos_token\n",
        "def formating_prompt_func(examples):\n",
        "    name = examples.get(\"name\")  # Use get to handle missing keys\n",
        "    text = examples.get(\"text\")  # Use get to handle missing keys\n",
        "\n",
        "    if name is not None and text is not None:  # Check if both keys are present\n",
        "        text = prompt_style.format(name, text, '')\n",
        "        # + EOS\n",
        "        return {\"text\": text}  # Return as a list for consistency\n",
        "    else:\n",
        "        return {\"text\": \"\"}  # Return empty list if either key is missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTDwY3WLNLkx"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B2mH_SpbBYK"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "class Course:\n",
        "    def __init__(self, name, credits, sections, category, prerequisites=[]):\n",
        "        self.name = name\n",
        "        self.credits = credits\n",
        "        self.sections = sections  # List of possible time slots\n",
        "        self.category = category  # e.g., 'core', 'elective', 'lab'\n",
        "        self.prerequisites = prerequisites\n",
        "\n",
        "def topological_sort(courses):\n",
        "    in_degree = {course: 0 for course in courses}\n",
        "    for course in courses:\n",
        "        for prereq in course.prerequisites:\n",
        "            in_degree[course] += 1\n",
        "\n",
        "    queue = deque([course for course in courses if in_degree[course] == 0])\n",
        "    sorted_courses = []\n",
        "\n",
        "    while queue:\n",
        "        course = queue.popleft()\n",
        "        sorted_courses.append(course)\n",
        "        for dependent in courses:\n",
        "            if course in dependent.prerequisites:\n",
        "                in_degree[dependent] -= 1\n",
        "                if in_degree[dependent] == 0:\n",
        "                    queue.append(dependent)\n",
        "\n",
        "    return sorted_courses\n",
        "\n",
        "def schedule_courses(courses, max_credits=18, taken_courses=set(), category_requirements={}):\n",
        "    sorted_courses = topological_sort(courses)\n",
        "    schedule = []\n",
        "    completed_courses = set(taken_courses)\n",
        "    category_credits_taken = {cat: 0 for cat in category_requirements}\n",
        "\n",
        "    while sorted_courses:\n",
        "        current_semester = []\n",
        "        current_credits = 0\n",
        "        occupied_time_slots = set()\n",
        "        remaining_courses = []\n",
        "\n",
        "        for course in sorted_courses:\n",
        "            if course.name in completed_courses:\n",
        "                continue\n",
        "\n",
        "            if any(prereq.name not in completed_courses for prereq in course.prerequisites):\n",
        "                remaining_courses.append(course)\n",
        "                continue\n",
        "\n",
        "            # Skip if category requirement is already fulfilled\n",
        "            if course.category in category_requirements and category_credits_taken[course.category] >= category_requirements[course.category]:\n",
        "                continue\n",
        "\n",
        "            # Choose an available section\n",
        "            chosen_section = None\n",
        "            for section in course.sections:\n",
        "                if section not in occupied_time_slots:\n",
        "                    chosen_section = section\n",
        "                    break\n",
        "\n",
        "            if chosen_section and current_credits + course.credits <= max_credits:\n",
        "                current_semester.append((course, chosen_section))\n",
        "                current_credits += course.credits\n",
        "                occupied_time_slots.add(chosen_section)\n",
        "                category_credits_taken[course.category] += course.credits\n",
        "            else:\n",
        "                remaining_courses.append(course)\n",
        "\n",
        "        if current_semester:\n",
        "            schedule.append(current_semester)\n",
        "            completed_courses.update(c.name for c, _ in current_semester)\n",
        "\n",
        "        sorted_courses = remaining_courses\n",
        "\n",
        "    return schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvFGMSlzbYMR"
      },
      "outputs": [],
      "source": [
        "# Example Usage\n",
        "\n",
        "def make_schedule():\n",
        "    c1 = Course(\"Math 101\", 3, [('Mon', '10:00-12:00'), ('Wed', '14:00-16:00')], 'core')\n",
        "    c2 = Course(\"CS 101\", 4, [('Tue', '14:00-16:00'), ('Thu', '10:00-12:00')], 'core', [c1])\n",
        "    c3 = Course(\"Physics 101\", 4, [('Mon', '12:00-14:00'), ('Fri', '16:00-18:00')], 'core')\n",
        "    c4 = Course(\"CS 102\", 4, [('Wed', '10:00-12:00'), ('Thu', '14:00-16:00')], 'core', [c2])\n",
        "    c5 = Course(\"Elective 1\", 3, [('Thu', '16:00-18:00'), ('Fri', '14:00-16:00')], 'elective')\n",
        "    c6 = Course(\"Elective 2\", 4, [('Fri', '10:00-12:00'), ('Mon', '08:00-10:00')], 'elective')\n",
        "    c7 = Course(\"Elective 3\", 3, [('Tue', '16:00-18:00'), ('Wed', '08:00-10:00')], 'elective')\n",
        "\n",
        "    courses = [c1, c2, c3, c4, c5, c6, c7]\n",
        "    taken_courses = {\"Math 101\"}\n",
        "    category_requirements = {'core': 12, 'elective': 6}  # Example: 12 credits core, 6 credits elective\n",
        "\n",
        "    schedule = schedule_courses(courses, taken_courses=taken_courses, category_requirements=category_requirements)\n",
        "\n",
        "    for i, semester in enumerate(schedule):\n",
        "        print(f\"Semester {i+1}:\")\n",
        "        total_credits = sum(course.credits for course, _ in semester)\n",
        "        print(f\"  Total Credits: {total_credits}\")\n",
        "        for course, section in semester:\n",
        "            print(f\"  {course.name} ({course.credits} credits, {course.category}) - {section}\")\n",
        "make_schedule()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljs9624vOAuQ"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "dataset = Dataset.from_json('/content/output.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjgi0NJVOEeg"
      },
      "outputs": [],
      "source": [
        "dataset[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScoKsH5y0mzV"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "dataset_finetune = dataset.map(formating_prompt_func)\n",
        "dataset_finetune[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvAQgLLQnrcp"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade cut_cross_entropy triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ekSMd8KoEXZ"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade torch torchvision torchaudio\n",
        "!pip install --upgrade cut_cross_entropy triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERMMFSFWGXzp"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset_finetune,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset_num_proc = 2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=1,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"text\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqDdx7BNTKAS"
      },
      "outputs": [],
      "source": [
        "trainer_start = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQJP9gYItV3w"
      },
      "outputs": [],
      "source": [
        "input = \"what is your name\"\n",
        "FastLanguageModel.for_inference(model)\n",
        "inputs = tokenizer([prompt_style.format(input,\"\",\"\")],return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=500,\n",
        "    use_cache=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QGehyMaqeiL"
      },
      "outputs": [],
      "source": [
        "Response = tokenizer.batch_decode(outputs)\n",
        "print(Response[0].split(\"##Response:\")[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkGofJANQuND"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# --- Function Mapping ---\n",
        "def execute_function_call(model_output):\n",
        "    # Extract function name\n",
        "    # Join the list of strings into a single string\n",
        "    model_output_str = \" \".join(model_output)\n",
        "    func_name = re.search(r\"<function>([^<]+)</function>\", model_output)\n",
        "    print(func_name.group(1).strip())\n",
        "    if not func_name:\n",
        "        return model_output  # No function detected\n",
        "\n",
        "    func_name = func_name.group(1).strip()\n",
        "\n",
        "    # Call the function (no args)\n",
        "    if func_name == 'make_schedule':\n",
        "        result = make_schedule()\n",
        "    else:\n",
        "        return f\"Error: Function '{func_name}' not found.\"\n",
        "\n",
        "    return f\"{func_name} result: {result}\"\n",
        "\n",
        "# --- Test the Model ---\n",
        "model_output = Response[0].split(\"##Response:\")[1]\n",
        "\n",
        "# Execute the function\n",
        "final_output = execute_function_call(model_output)\n",
        "print(final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oCR8JjcSPZM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def execute_function_call(model_output):\n",
        "    # Extract day and time ranges\n",
        "    day_time_ranges = re.findall(r'([A-Za-z]+)\\s(\\d{1,2}:\\d{2}-\\d{1,2}:\\d{2})', model_output)\n",
        "\n",
        "    if not day_time_ranges:\n",
        "        print(model_output)  # No day and time ranges detected\n",
        "\n",
        "    current_day = datetime.now().strftime(\"%A\")\n",
        "    current_time = datetime.now().time()\n",
        "\n",
        "    print(\"Extracted Day & Time Ranges:\", day_time_ranges)\n",
        "    print(\"Current Day:\", current_day)\n",
        "    print(\"Current Time:\", current_time)\n",
        "\n",
        "    # Function to check if current time is within a given time range\n",
        "    def is_time_in_range(time_range, current_time):\n",
        "        start_str, end_str = time_range.split('-')\n",
        "        start = datetime.strptime(start_str, \"%H:%M\").time()\n",
        "        end = datetime.strptime(end_str, \"%H:%M\").time()\n",
        "        return start <= current_time <= end\n",
        "\n",
        "    # Check each extracted day and time range\n",
        "    for day, time_range in day_time_ranges:\n",
        "        if day.lower() == current_day.lower():\n",
        "            print(f\"\\nToday is {current_day}, checking time range: {time_range}\")\n",
        "            if is_time_in_range(time_range, current_time):\n",
        "                print(\"✅ lecturer is available\")\n",
        "            else:\n",
        "                print(\"❌ lecturer is unavailable at the moment\")\n",
        "        else:\n",
        "            print(f\"\\nToday is {current_day}, skipping {day}'s range: {time_range}\")\n",
        "model_output = Response[0].split(\"##Response:\")[1]\n",
        "\n",
        "final_output = execute_function_call(model_output)\n",
        "print(final_output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}